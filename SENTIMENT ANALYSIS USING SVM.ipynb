{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44d54e39-541e-4537-9ff2-b6a476063e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import numpy as np \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt \n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14) \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f6c0192-4c65-418a-af9a-c9da9fba1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and preprocessing the data #Read in the data set: \n",
    "with open(\"full_set.txt\") as f: \n",
    "    content = f.readlines() \n",
    "#Remove leading and trailing white space: \n",
    "    content = [x.strip() for x in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5cb3c27-da7e-4273-bec5-dce42f7266b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the sentences from the labels: \n",
    "sentences = [x.split(\"\\t\")[0] for x in content] \n",
    "labels = [x.split(\"\\t\")[1] for x in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53ca7d9d-ca16-4b10-a206-cf07b00653fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the labels from '0 versus 1' to '-1 versus 1':\n",
    "y = np.array(labels, dtype='int8') \n",
    "y = 2*y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9fe8904-643f-49c7-a56e-5c3cf6231810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters in removal_list replaced by ' '. \n",
    "def full_remove(x, removal_list): \n",
    "    for w in removal_list: \n",
    "        x = x.replace(w, ' ') \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e12056d1-d5df-4c29-950f-9371ab97170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove digits: \n",
    "digits = [str(x) for x in range(10)] \n",
    "digit_less = [full_remove(x, digits) for x in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4457978d-f2bb-4d53-b0e9-838f6a509e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuation: \n",
    "punc_less = [full_remove(x, list(string.punctuation)) for x in digit_less]\n",
    "\n",
    "#Make everything lower-case: \n",
    "sents_lower = [x.lower() for x in punc_less] \n",
    "#Define our stop words: \n",
    "stop_set = set(['the', 'a', 'an', 'i', 'he', 'she', 'they', 'to', 'of', 'it', 'from'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c8328cf-185b-4a0c-aa85-075937168b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop words \n",
    "sents_split = [x.split() for x in sents_lower] \n",
    "sents_processed = [\" \".join(list(filter(lambda a: a not in stop_set, x))) for x in sents_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "827787cb-295a-4ff2-8ce6-4b3521ca962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform to bag of words representation: \n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, \n",
    "                             preprocessor = None, stop_words = None, max_features = 4500) \n",
    "data_features = vectorizer.fit_transform(sents_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bba7bfd-e4cb-4569-b8d8-560bf8b8a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append '1' to the end of each vector. \n",
    "data_mat = data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1769567a-8c42-45cd-9b03-2f380cf13298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  (2500, 4500)\n",
      "test data:  (500, 4500)\n"
     ]
    }
   ],
   "source": [
    "#Split the data into testing and training sets: \n",
    "np.random.seed(0) \n",
    "test_inds = np.append(np.random.choice((np.where(y==-1))[0], 250, replace=False), np.random.choice((np.where(y==1))[0], 250, replace=False)) \n",
    "train_inds = list(set(range(len(labels))) - set(test_inds)) \n",
    "train_data = data_mat[train_inds,] \n",
    "train_labels = y[train_inds] \n",
    "test_data = data_mat[test_inds,] \n",
    "test_labels = y[test_inds] \n",
    "print(\"train data: \", train_data.shape) \n",
    "print(\"test data: \", test_data.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee759e5b-afaf-491b-b4b8-f515ce7700c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting a support vector machine to the data \n",
    "def fit_classifier(C_value=1.0): \n",
    "    clf = svm.LinearSVC(C=C_value, loss='hinge') \n",
    "    clf.fit(train_data,train_labels) \n",
    "    # Get predictions on training data \n",
    "    train_preds = clf.predict(train_data) \n",
    "    train_error = float(np.sum((train_preds > 0.0) != (train_labels > 0.0)))/len(train_labels) \n",
    "    # Get predictions on test data \n",
    "    test_preds = clf.predict(test_data) \n",
    "    test_error = float(np.sum((test_preds > 0.0) != (test_labels > 0.0)))/len(test_labels) \n",
    "    return train_error, test_error \n",
    "    cvals = [0.01,0.1,1.0,10.0,100.0,1000.0,10000.0] \n",
    "    for c in cvals: \n",
    "        train_error, test_error = fit_classifier(c) \n",
    "        print (\"Error rate for C = %0.2f: train %0.3f test %0.3f\" % (c, train_error, test_error)) \n",
    "    #We see that the minimum test error is for C = 1.0. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68ee11e8-2e3d-426b-a700-6d42bd91da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Evaluating C by k-fold cross-validation\n",
    "def cross_validation_error(x,y,C_value,k): \n",
    "    n = len(y) \n",
    "# Randomly shuffle indices \n",
    "    indices = np.random.permutation(n) \n",
    "# Initialize error \n",
    "    err = 0.0 \n",
    "# Iterate over partitions\n",
    "    for i in range(k): \n",
    "        # Partition indices \n",
    "        test_indices = indices[int(i*(n/k)):int((i+1)*(n/k) - 1)] \n",
    "        train_indices = np.setdiff1d(indices, test_indices)\n",
    "        # Train classifier with parameter c \n",
    "        clf = svm.LinearSVC(C=C_value, loss='hinge') \n",
    "        clf.fit(x[train_indices], y[train_indices])\n",
    "        # Get predictions on test partition \n",
    "        preds = clf.predict(x[test_indices])\n",
    "        # Compute error \n",
    "        err += float(np.sum((preds > 0.0) != (y[test_indices] > 0.0)))/len(test_indices) \n",
    "        return err/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "138ec0eb-b285-498b-8271-eaf0a2e33aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_validation_error: \n",
      "0.10328262610088071\n",
      "cross_validation_error: \n",
      "0.06690705128205128\n",
      "cross_validation_error: \n",
      "0.045272435897435896\n",
      "cross_validation_error: \n",
      "0.036072144288577156\n",
      "cross_validation_error: \n",
      "0.030120481927710843\n",
      "cross_validation_error: \n",
      "0.02447833065810594\n",
      "cross_validation_error: \n",
      "0.02451768488745981\n",
      "cross_validation_error: \n",
      "0.022544283413848634\n"
     ]
    }
   ],
   "source": [
    "#Let us print out the eoees or ifferen vaues of k \n",
    "for k in range(2,10): \n",
    "    print(\"cross_validation_error: \") \n",
    "    print(cross_validation_error(train_data,train_labels,1.0,k))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
